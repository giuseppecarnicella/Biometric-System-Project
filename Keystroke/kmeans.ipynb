{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv,sys\n",
    "import math,random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DSL-StrongPasswordData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = data[\"subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateEER(user_scores, imposter_scores):\n",
    "    labels = [0]*len(user_scores) + [1]*len(imposter_scores)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, user_scores + imposter_scores)\n",
    "    missrates = 1 - tpr\n",
    "    farates = fpr\n",
    "    dists = missrates - farates\n",
    "    idx1 = np.argmin(dists[dists >= 0])\n",
    "    idx2 = np.argmax(dists[dists < 0])\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "    #An point in n dimensional space\n",
    "    def __init__(self, coords):\n",
    "    #coords - A list of values, one per dimension\n",
    "        self.coords = coords\n",
    "        self.n = len(coords)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    #A set of points and their centroid\n",
    "\n",
    "    def __init__(self, points):\n",
    "    #points - A list of point objects\n",
    "\n",
    "        if len(points) == 0: \n",
    "            raise Exception(\"ILLEGAL: empty cluster\")\n",
    "        # The points that belong to this cluster\n",
    "        self.points = points\n",
    "\n",
    "        # The dimensionality of the points in this cluster\n",
    "        self.n = points[0].n\n",
    "    \n",
    "        # Assert that all points are of the same dimensionality\n",
    "        for p in points:\n",
    "            if p.n != self.n: raise Exception(\"ILLEGAL: wrong dimensions\")\n",
    "    \n",
    "        # Set up the initial centroid (this is usually based off one point)\n",
    "        self.centroid = self.calculateCentroid()\n",
    "\n",
    "    def __repr__(self):\n",
    "    #String representation of this object\n",
    "        return str(self.points)\n",
    "\n",
    "    def update(self, points):\n",
    "    #Returns the distance between the previous centroid and the new after\n",
    "    #recalculating and storing the new centroid.\n",
    "        old_centroid = self.centroid\n",
    "        self.points = points\n",
    "        self.centroid = self.calculateCentroid()\n",
    "        shift = getDistance(old_centroid, self.centroid) \n",
    "        return shift\n",
    "\n",
    "    def calculateCentroid(self):\n",
    "    #Finds a virtual center point for a group of n-dimensional points\n",
    "        numPoints = len(self.points)\n",
    "        # Get a list of all coordinates in this cluster\n",
    "        coords = [p.coords for p in self.points]\n",
    "        # Reformat that so all x's are together, all y'z etc.\n",
    "        unzipped = zip(*coords)\n",
    "        # Calculate the mean for each dimension\n",
    "        centroid_coords = [math.fsum(dList)/numPoints for dList in unzipped]\n",
    "\n",
    "        return Point(centroid_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistance(a, b):\n",
    "\n",
    "#Euclidean distance between two n-dimensional points.\n",
    "#Note: This can be very slow and does not scale well\n",
    "    #if a.n != b.n:\n",
    "    #    raise Exception(\"ILLEGAL: non comparable points\")\n",
    "\n",
    "    ret = reduce(lambda x,y: x + pow((a.coords[y]-b.coords[y]), 2),range(a.n),0.0)\n",
    "    return math.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testing(clusters,test_genuine,test_imposter):\n",
    "    user_scores = []\n",
    "    imposter_scores = []\n",
    "    for i in range(len(test_genuine)):\n",
    "        min_distance = 1e+10\n",
    "        for j in range(len(clusters)):\n",
    "            cur_score = getDistance(test_genuine[i],clusters[j].centroid)\n",
    "            if cur_score < min_distance:\n",
    "                min_distance = cur_score\n",
    "        user_scores.append(min_distance)\n",
    "            \n",
    "    for i in range(len(test_imposter)):\n",
    "        min_distance = 1e+10\n",
    "        for j in range(len(clusters)):\n",
    "            cur_score = getDistance(test_imposter[i],clusters[j].centroid)\n",
    "            if cur_score < min_distance:\n",
    "                min_distance = cur_score\n",
    "        imposter_scores.append(min_distance)\n",
    "    return user_scores,imposter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(points, k, cutoff):\n",
    "\n",
    "    # Pick out k random points to use as our initial centroids\n",
    "    initial = random.sample(points, k)\n",
    "\n",
    "    # Create k clusters using those centroids\n",
    "    clusters = [Cluster([p]) for p in initial]\n",
    "\n",
    "    # Loop through the dataset until the clusters stabilize\n",
    "    loopCounter = 0\n",
    "    while True:\n",
    "        # Create a list of lists to hold the points in each cluster\n",
    "        lists = [ [] for c in clusters]\n",
    "        clusterCount = len(clusters)\n",
    "\n",
    "        # Start counting loops\n",
    "        loopCounter += 1\n",
    "        # For every point in the dataset ...\n",
    "        for p in points:\n",
    "            # Get the distance between that point and the centroid of the first\n",
    "            # cluster.\n",
    "            smallest_distance = getDistance(p, clusters[0].centroid)\n",
    "\n",
    "            # Set the cluster this point belongs to\n",
    "            clusterIndex = 0\n",
    "\n",
    "            # For the remainder of the clusters ...\n",
    "            for i in range(clusterCount - 1):\n",
    "                # calculate the distance of that point to each other cluster's\n",
    "                # centroid.\n",
    "                distance = getDistance(p, clusters[i+1].centroid)\n",
    "                # If it's closer to that cluster's centroid update what we\n",
    "                # think the smallest distance is, and set the point to belong\n",
    "                # to that cluster\n",
    "                if distance < smallest_distance:\n",
    "                    smallest_distance = distance\n",
    "                    clusterIndex = i+1\n",
    "            lists[clusterIndex].append(p)\n",
    "\n",
    "        # Set our biggest_shift to zero for this iteration\n",
    "        biggest_shift = 0.0\n",
    "\n",
    "        # As many times as there are clusters ...\n",
    "        for i in range(clusterCount):\n",
    "            # Calculate how far the centroid moved in this iteration\n",
    "            shift = clusters[i].update(lists[i])\n",
    "            # Keep track of the largest move from all cluster centroid updates\n",
    "            biggest_shift = max(biggest_shift, shift)\n",
    "\n",
    "        # If the centroids have stopped moving much, say we're done!\n",
    "        if biggest_shift < cutoff:\n",
    "            print (\"Converged after %s iterations\" % loopCounter)\n",
    "            break\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "        eers = []\n",
    "        k = 3\n",
    "        cut_off = 0.5\n",
    "        for subject in subjects:\n",
    "            \n",
    "            user_scores = []\n",
    "            imposter_scores = []\n",
    "    \n",
    "            # Consider current subject as genuine and rest as imposters\n",
    "            genuine_user_data = data.loc[data.subject == subject, \"H.period\":\"H.Return\"]\n",
    "            imposter_data = data.loc[data.subject != subject, :]\n",
    "    \n",
    "            # genuine user's first 200 time vectors for training\n",
    "            train = genuine_user_data[:200]\n",
    "            train = train.values\n",
    "            train = np.array(train)\n",
    "            train = list(train)\n",
    "            temp = []\n",
    "            for p in train:\n",
    "                temp.append(list(p))\n",
    "            train = temp\n",
    "            points = []\n",
    "            for p in train:\n",
    "                points.append(Point([float(elements) for elements in p]))\n",
    "            temp = []\n",
    "            # True set (200 records)\n",
    "            test_genuine = genuine_user_data[200:]\n",
    "            test_genuine = test_genuine.values\n",
    "            test_genuine = np.array(test_genuine)\n",
    "            test_genuine = list(test_genuine)\n",
    "            for p in test_genuine:\n",
    "                temp.append(list(p))\n",
    "            test_genuine = temp\n",
    "            # False set (250 records, 5 per imposter, 50 imposters in all)\n",
    "            temp = []\n",
    "            test_imposter = imposter_data.groupby(\"subject\").head(5).loc[:, \"H.period\":\"H.Return\"]\n",
    "            test_imposter = test_imposter.values\n",
    "            test_imposter = np.array(test_imposter)\n",
    "            test_imposter = list(test_imposter)\n",
    "            for p in test_imposter:\n",
    "                temp.append(list(p))\n",
    "            test_imposter = temp\n",
    "            points_test_genuine = []\n",
    "            points_test_imposter = []\n",
    "            for p in test_genuine:\n",
    "                points_test_genuine.append(Point([float(elements) for elements in p]))\n",
    "            for p in test_imposter:\n",
    "                points_test_imposter.append(Point([float(elements) for elements in p]))\n",
    "            clusters = kmeans(points,k,cut_off)\n",
    "            \n",
    "            user_scores,imposter_scores = testing(clusters,points_test_genuine,points_test_imposter)\n",
    "    \n",
    "            eers.append(evaluateEER(user_scores, imposter_scores))\n",
    "        \n",
    "        return np.mean(eers), np.std(eers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 3 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 2 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 11 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n",
      "Converged after 1 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1544805981066186, 0.0743659100956529)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
